{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "448d82f3-db54-451a-bfbf-0f89b06b79a9",
   "metadata": {},
   "source": [
    "[Problem 1] Execution of various methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5f0aa7-3096-4a19-af77-9ed08cb0c522",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding,SimpleRNN,LSTM\n",
    "from keras.layers import LSTM\n",
    "from keras.datasets import imdb\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5607095b-dd57-481c-bb36-02ccd420d27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.convolutional import Conv3D\n",
    "from keras.layers import LSTM  \n",
    "from keras.layers import BatchNormalization\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "from keras.utils.data_utils import pad_sequences\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7b6e51-4dbe-450a-80e7-35f4e603a386",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 20000\n",
    "# cut texts after this number of words (among top max_features most common words)\n",
    "maxlen = 80\n",
    "batch_size = 32\n",
    "\n",
    "print('Loading data...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9672390-c267-4dbd-9aee-e030b23327b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=15,\n",
    "          validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c6e42f-1287-4714-9ce6-bd793039b855",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59795192-116d-4447-98ab-94c026f994c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Build model Simple RNN')\n",
    "simplernnmodel = Sequential()\n",
    "\n",
    "simplernnmodel.add(Embedding(max_features, 128))\n",
    "simplernnmodel.add(SimpleRNN(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "simplernnmodel.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "simplernnmodel.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "simplernnmodel.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=15,\n",
    "          validation_data=(x_test, y_test))\n",
    "score, acc = simplernnmodel.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Simple RNN Test score:', score)\n",
    "print('Simpke RNN Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7beae50c-a4e5-46fb-94d1-bae837766f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a371c498-c085-4807-b032-dcea93357638",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Build model GRU')\n",
    "grumodel = Sequential()\n",
    "\n",
    "grumodel.add(Embedding(max_features, 128))\n",
    "grumodel.add(GRU(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "grumodel.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "grumodel.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "grumodel.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=15,\n",
    "          validation_data=(x_test, y_test))\n",
    "score, acc = grumodel.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('GRU Test score:', score)\n",
    "print('GRU Test accuracy:', acc)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5643e9-4463-4ff9-8967-bfb49c3b8ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_movies(n_samples=1200, n_frames=15):\n",
    "    row = 80\n",
    "    col = 80\n",
    "    noisy_movies = np.zeros((n_samples, n_frames, row, col, 1), dtype=np.float)\n",
    "    shifted_movies = np.zeros((n_samples, n_frames, row, col, 1),dtype=np.float)\n",
    "    for i in range(n_samples):\n",
    "        n = np.random.randint(3, 8)\n",
    "        for j in range(n):\n",
    "            xstart = np.random.randint(20, 60)\n",
    "            ystart = np.random.randint(20, 60)\n",
    "            directionx = np.random.randint(0, 3) - 1\n",
    "            directiony = np.random.randint(0, 3) - 1\n",
    "            w = np.random.randint(2, 4)\n",
    "            for t in range(n_frames):\n",
    "                x_shift = xstart + directionx * t\n",
    "                y_shift = ystart + directiony * t\n",
    "                noisy_movies[i, t, x_shift - w: x_shift + w,y_shift - w: y_shift + w, 0] += 1\n",
    "                if np.random.randint(0, 2):\n",
    "                    noise_f = (-1)**np.random.randint(0, 2)\n",
    "                    noisy_movies[i, t,x_shift - w - 1: x_shift + w + 1,y_shift - w - 1: y_shift + w + 1,0] += noise_f * 0.1\n",
    "                x_shift = xstart + directionx * (t + 1)\n",
    "                y_shift = ystart + directiony * (t + 1)\n",
    "                shifted_movies[i, t, x_shift - w: x_shift + w,y_shift - w: y_shift + w, 0] += 1\n",
    "    noisy_movies = noisy_movies[::, ::, 20:60, 20:60, ::]\n",
    "    shifted_movies = shifted_movies[::, ::, 20:60, 20:60, ::]\n",
    "    noisy_movies[noisy_movies >= 1] = 1\n",
    "    shifted_movies[shifted_movies >= 1] = 1\n",
    "    return noisy_movies, shifted_movies\n",
    "\n",
    "noisy_movies, shifted_movies = generate_movies(n_samples=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb17fb6-7a3b-47d5-9eea-a0d7d7244c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 1\n",
    "x = noisy_movies[index]\n",
    "fig = plt.figure()\n",
    "viewer = fig.add_subplot(111)\n",
    "plt.ion()\n",
    "fig.show()\n",
    "for i in range(len(x)):\n",
    "    viewer.clear()\n",
    "    viewer.imshow(x[i])\n",
    "    plt.pause(.1)\n",
    "    fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd08e87-dd59-4dbb-92ee-a3429b4fd368",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.layers import ConvLSTM2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91914a25-f485-4247-9a64-aa36bf15408e",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = Sequential()\n",
    "seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),input_shape=(None, 40, 40, 1),padding='same', return_sequences=True))\n",
    "seq.add(BatchNormalization())\n",
    "seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),padding='same', return_sequences=True))\n",
    "seq.add(BatchNormalization())\n",
    "seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),padding='same', return_sequences=True))\n",
    "seq.add(BatchNormalization())\n",
    "seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),padding='same', return_sequences=True))\n",
    "seq.add(BatchNormalization())\n",
    "seq.add(Conv3D(filters=1, kernel_size=(3, 3, 3),activation='sigmoid',padding='same', data_format='channels_last'))\n",
    "seq.compile(loss='binary_crossentropy', optimizer='adadelta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8f7778-85e5-4728-8dbd-6bce13023c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq.fit(noisy_movies[:100], shifted_movies[:100], batch_size=10,epochs=1, validation_split=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a73986-1f75-429e-ba5d-116456dfaf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 1004\n",
    "track = noisy_movies[index][:7, ::, ::, ::] \n",
    "track2 = noisy_movies[index][::, ::, ::, ::]\n",
    "for j in range(16):\n",
    "    new_pos = seq.predict(track[np.newaxis, ::, ::, ::, ::])\n",
    "    new = new_pos[::, -1, ::, ::, ::]\n",
    "    track = np.concatenate((track, new), axis=0)\n",
    "for i in range(15):\n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "    ax = fig.add_subplot(121)\n",
    "    if i >= 7:\n",
    "        ax.text(1, 3, 'Predictions !', fontsize=20, color='w')\n",
    "    else:\n",
    "        ax.text(1, 3, 'Initial trajectory', fontsize=20)\n",
    "    toplot = track[i, ::, ::, 0]\n",
    "    plt.imshow(toplot)\n",
    "    ax = fig.add_subplot(122)\n",
    "    plt.text(1, 3, 'Ground truth', fontsize=20)\n",
    "    toplot = track2[i, ::, ::, 0]\n",
    "    if i >= 2:\n",
    "        toplot = shifted_movies[index][i - 1, ::, ::, 0]\n",
    "    plt.imshow(toplot)\n",
    "    plt.savefig('%i_animate.png' % (i + 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
