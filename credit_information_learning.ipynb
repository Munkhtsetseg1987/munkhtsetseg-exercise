{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e02d1d6-6ea4-4964-8049-113b3d6d687f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cat cols: 59\n",
      "Number of numerical cols: 22\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'utils/missing_values.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 86\u001b[0m\n\u001b[0;32m     83\u001b[0m         df[col] \u001b[38;5;241m=\u001b[39m df[col]\u001b[38;5;241m.\u001b[39mfillna(df[col]\u001b[38;5;241m.\u001b[39mmedian())\n\u001b[0;32m     84\u001b[0m         missing_values[col] \u001b[38;5;241m=\u001b[39m (df[col]\u001b[38;5;241m.\u001b[39mmedian())\n\u001b[1;32m---> 86\u001b[0m joblib\u001b[38;5;241m.\u001b[39mdump(missing_values, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutils/missing_values.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     88\u001b[0m \u001b[38;5;66;03m#### label encoding ####\u001b[39;00m\n\u001b[0;32m     89\u001b[0m encoders \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\OnlineTraining\\Lib\\site-packages\\joblib\\numpy_pickle.py:552\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(value, filename, compress, protocol, cache_size)\u001b[0m\n\u001b[0;32m    550\u001b[0m         NumpyPickler(f, protocol\u001b[38;5;241m=\u001b[39mprotocol)\u001b[38;5;241m.\u001b[39mdump(value)\n\u001b[0;32m    551\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_filename:\n\u001b[1;32m--> 552\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    553\u001b[0m         NumpyPickler(f, protocol\u001b[38;5;241m=\u001b[39mprotocol)\u001b[38;5;241m.\u001b[39mdump(value)\n\u001b[0;32m    554\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'utils/missing_values.pkl'"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import joblib\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import (RandomForestClassifier,\n",
    "                              GradientBoostingClassifier)\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "gc.enable()\n",
    "\n",
    "### Data load ####\n",
    "DEBUG = False\n",
    "REMOVE_OUTLIERS=True\n",
    "\n",
    "if DEBUG:\n",
    "    train_df = pd.read_csv('import/train.csv', nrows=1000)\n",
    "    test_df = pd.read_csv('import/train.csv', nrows=1000)\n",
    "else:\n",
    "    train_df = pd.read_csv('import/train.csv')\n",
    "    test_df = pd.read_csv('import/train.csv')\n",
    "\n",
    "train_df['isTrain'] = 'Train'\n",
    "test_df['isTrain'] = 'Test'\n",
    "\n",
    "test_df['TARGET'] = np.nan\n",
    "\n",
    "df = pd.concat([train_df, test_df[train_df.columns]], axis=0)\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "del train_df, test_df\n",
    "gc.collect()\n",
    "\n",
    "### Data preprocessing ###\n",
    "num_cols = []\n",
    "cat_cols = []\n",
    "should_be_encode = []\n",
    "not_useful_cols = ['SK_ID_CURR', 'TARGET', 'isTrain']\n",
    "\n",
    "for col in df.columns:\n",
    "    if col not in not_useful_cols:\n",
    "        unique_len = len(df[col].unique())\n",
    "        data_type = df[col].dtype\n",
    "\n",
    "        if unique_len<=20 and data_type!=\"object\":\n",
    "            cat_cols.append(col)\n",
    "        elif data_type=='object':\n",
    "            should_be_encode.append(col)\n",
    "        else:\n",
    "            num_cols.append(col)\n",
    "\n",
    "print('Number of cat cols:', len(cat_cols+should_be_encode))\n",
    "print('Number of numerical cols:', len(num_cols))\n",
    "\n",
    "### Fill missing values ###\n",
    "missing_values = {}\n",
    "for col in num_cols:\n",
    "    num_missing_values = df[col].isnull().sum()\n",
    "    if num_missing_values>0:\n",
    "        df[col] = df[col].fillna(np.nanmean(df[col].values))\n",
    "        missing_values[col] = np.nanmean(df[col].values)\n",
    "\n",
    "for col in should_be_encode:\n",
    "    num_missing_values = df[col].isnull().sum()\n",
    "    if num_missing_values > 0:\n",
    "        df[col] = df[col].fillna(df[col].mode())\n",
    "        missing_values[col] = (df[col].mode())\n",
    "\n",
    "for col in cat_cols:\n",
    "    num_missing_values = df[col].isnull().sum()\n",
    "    if num_missing_values > 0:\n",
    "        #df[col] = df[col].fillna(df[col].mode())\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "        missing_values[col] = (df[col].median())\n",
    "\n",
    "joblib.dump(missing_values, 'utils/missing_values.pkl')\n",
    "\n",
    "#### label encoding ####\n",
    "encoders = {}\n",
    "for col in should_be_encode:\n",
    "    encoder = LabelEncoder().fit(df[col])\n",
    "    encoders[col] = encoder\n",
    "    df[col] = encoder.transform(df[col])\n",
    "\n",
    "joblib.dump(encoders, \"utils/encoders.pkl\",)\n",
    "\n",
    "\n",
    "\n",
    "### verify ####\n",
    "for col in cat_cols+should_be_encode+num_cols:\n",
    "    if df[col].isnull().sum()>0:\n",
    "        print(col, df[col].dtype, df[col].isnull().sum())\n",
    "\n",
    "cat_cols = cat_cols + should_be_encode\n",
    "del should_be_encode\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "#### onehot encoding ####\n",
    "dummy_cols = []\n",
    "map_dummy = {}\n",
    "for col in tqdm(cat_cols, total=len(cat_cols)):\n",
    "    for value in tqdm(df[col].unique()):\n",
    "        df[f'dummy_{col}_{value}'] = 0\n",
    "        df.loc[df[col]==value, f'dummy_{col}_{value}'] = 1\n",
    "        dummy_cols.append(f'dummy_{col}_{value}')\n",
    "        map_dummy[col] = f\"dummy_{col}_{value}\"\n",
    "\n",
    "joblib.dump(map_dummy, 'utils/map_dummy.pkl')\n",
    "\n",
    "del cat_cols\n",
    "gc.collect()\n",
    "\n",
    "### outlier remove ####\n",
    "train_df = df.loc[df['isTrain']=='Train'].reset_index(drop=True)\n",
    "test_df = df.loc[df['isTrain']=='Test'].reset_index(drop=True)\n",
    "\n",
    "del df\n",
    "gc.collect()\n",
    "\n",
    "outlier_idx = []\n",
    "for col in num_cols:\n",
    "    z_score = stats.zscore(train_df[col])\n",
    "    outlier_idx = outlier_idx + list(train_df.loc[(np.abs(z_score)>3)].index)\n",
    "\n",
    "outlier_idx = list(set(outlier_idx))\n",
    "\n",
    "if REMOVE_OUTLIERS:\n",
    "    train_df = train_df.drop(index=outlier_idx,\n",
    "                             axis=0).reset_index(drop=True)\n",
    "\n",
    "joblib.dump(num_cols, 'utils/num_cols.pkl')\n",
    "joblib.dump(dummy_cols, 'utils/dummy_cols.pkl')\n",
    "\n",
    "### Modelling ###\n",
    "skf = StratifiedKFold(n_splits=5,\n",
    "                      shuffle=True,\n",
    "                      random_state=42)\n",
    "\n",
    "models = []\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(train_df,\n",
    "                                    train_df['TARGET'],\n",
    "                                    groups=train_df['TARGET'])):\n",
    "    train_set = train_df.loc[train_idx]\n",
    "    val_set = train_df.loc[val_idx]\n",
    "\n",
    "    model = LogisticRegression().fit(train_set[num_cols+dummy_cols],\n",
    "                                     train_set['TARGET'])\n",
    "    models.append(model)\n",
    "\n",
    "    y_pred = model.predict_proba(val_set[num_cols+dummy_cols])[:, 1]\n",
    "\n",
    "    auc_score = roc_auc_score(val_set['TARGET'], y_pred)\n",
    "    print(f\"FOLD-{fold}: AUC score={np.round(auc_score, 3)}\")\n",
    "\n",
    "joblib.dump(models, 'utils/models.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3183931-ef92-404a-8fc8-8bb2ef1d4f30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
